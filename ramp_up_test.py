#!/usr/bin/env python3
"""
é˜¶æ¢¯å¼å‹åŠ›æµ‹è¯•è„šæœ¬
é€æ­¥å¢åŠ å¹¶å‘ç”¨æˆ·æ•°ï¼Œç›´åˆ°æœåŠ¡å™¨è¾¾åˆ°æ€§èƒ½æé™
"""

import asyncio
import json
import time
import psutil
from datetime import datetime
from typing import Dict, Any
import aiohttp

from src.load_test.client import ChatBotLoadTester


class SystemMonitor:
    """ç³»ç»Ÿèµ„æºç›‘æ§å™¨"""

    def __init__(self):
        self.cpu_data = []
        self.memory_data = []
        self.start_time = time.time()

    def get_system_stats(self) -> Dict[str, float]:
        """è·å–ç³»ç»Ÿèµ„æºä½¿ç”¨æƒ…å†µ"""
        cpu_percent = psutil.cpu_percent(interval=0.1)
        memory = psutil.virtual_memory()
        return {
            "cpu_percent": cpu_percent,
            "cpu_idle": 100 - cpu_percent,
            "memory_percent": memory.percent,
            "memory_used": memory.used / (1024**3),  # GB
            "memory_total": memory.total / (1024**3),  # GB
            "timestamp": time.time() - self.start_time
        }

    def record_stats(self):
        """è®°å½•ç³»ç»ŸçŠ¶æ€"""
        stats = self.get_system_stats()
        self.cpu_data.append(stats)
        self.memory_data.append(stats)


class RampUpLoadTester:
    """é˜¶æ¢¯å¼è´Ÿè½½æµ‹è¯•å™¨"""

    def __init__(self, base_url: str = "http://localhost:8000"):
        self.base_url = base_url
        self.results = []
        self.system_monitor = SystemMonitor()
        self.test_messages = [
            "Hello, how are you?",
            "What can you help me with?",
            "Tell me about artificial intelligence",
            "How does machine learning work?",
            "What are the benefits of Python?",
            "Explain the concept of async programming",
            "What is the difference between FastAPI and Flask?",
            "How do you optimize web application performance?",
            "What are microservices?",
            "Explain the concept of serverless computing",
        ]

    async def health_check(self) -> bool:
        """æ£€æŸ¥æœåŠ¡å™¨å¥åº·çŠ¶æ€"""
        try:
            async with aiohttp.ClientSession() as session:
                async with session.get(f"{self.base_url}/health") as response:
                    return response.status == 200
        except:
            return False

    async def get_server_metrics(self) -> Dict[str, Any]:
        """è·å–æœåŠ¡å™¨æŒ‡æ ‡"""
        try:
            async with aiohttp.ClientSession() as session:
                async with session.get(f"{self.base_url}/metrics") as response:
                    if response.status == 200:
                        return await response.json()
        except:
            pass
        return {}

    async def run_single_test_phase(self,
                                  concurrency: int,
                                  duration: int = 30,
                                  phase_name: str = "") -> Dict[str, Any]:
        """è¿è¡Œå•ä¸ªæµ‹è¯•é˜¶æ®µ"""
        print(f"\nğŸš€ å¼€å§‹æµ‹è¯•é˜¶æ®µ: {phase_name}")
        print(f"   å¹¶å‘ç”¨æˆ·æ•°: {concurrency}")
        print(f"   æµ‹è¯•æ—¶é•¿: {duration}ç§’")

        # è®°å½•å¼€å§‹æ—¶çš„ç³»ç»ŸçŠ¶æ€
        start_time = time.time()
        start_server_metrics = await self.get_server_metrics()
        start_system_stats = self.system_monitor.get_system_stats()

        # è¿è¡Œè´Ÿè½½æµ‹è¯•
        async with ChatBotLoadTester(self.base_url) as tester:
            # è¿è¡Œå‹æµ‹
            results = await tester.run_ramp_up_test(
                max_concurrency=concurrency,
                ramp_up_duration=min(10, duration // 3),
                duration=duration,
                messages=self.test_messages
            )

            # è®°å½•ç»“æŸæ—¶çš„ç³»ç»ŸçŠ¶æ€
            end_time = time.time()
            end_server_metrics = await self.get_server_metrics()
            end_system_stats = self.system_monitor.get_system_stats()

            # è®¡ç®—æ€§èƒ½æŒ‡æ ‡
            metrics = results["metrics"]
            test_results = {
                "phase": phase_name,
                "concurrency": concurrency,
                "duration": duration,
                "start_time": start_time,
                "end_time": end_time,

                # è¯·æ±‚æŒ‡æ ‡
                "total_requests": metrics["total_requests"],
                "successful_requests": metrics["successful_requests"],
                "failed_requests": metrics["failed_requests"],
                "success_rate": metrics["success_rate"],

                # æ€§èƒ½æŒ‡æ ‡
                "avg_response_time": metrics["average_response_time"],
                "min_response_time": metrics["min_response_time"],
                "max_response_time": metrics["max_response_time"],
                "throughput": metrics["throughput"],

                # ç³»ç»Ÿèµ„æº
                "start_cpu_percent": start_system_stats["cpu_percent"],
                "start_cpu_idle": start_system_stats["cpu_idle"],
                "start_memory_percent": start_system_stats["memory_percent"],
                "end_cpu_percent": end_system_stats["cpu_percent"],
                "end_cpu_idle": end_system_stats["cpu_idle"],
                "end_memory_percent": end_system_stats["memory_percent"],

                # æœåŠ¡å™¨æŒ‡æ ‡
                "start_total_requests": start_server_metrics.get("total_requests", 0),
                "end_total_requests": end_server_metrics.get("total_requests", 0),

                # é”™è¯¯ä¿¡æ¯
                "errors": metrics["errors"][:5] if metrics["errors"] else []  # åªä¿ç•™å‰5ä¸ªé”™è¯¯
            }

            # æ‰“å°ç»“æœ
            print(f"   ğŸ“Š æµ‹è¯•ç»“æœ:")
            print(f"      âœ“ æˆåŠŸç‡: {metrics['success_rate']:.1f}%")
            print(f"      âœ“ å¹³å‡å“åº”æ—¶é—´: {metrics['average_response_time']:.3f}s")
            print(f"      âœ“ ååé‡: {metrics['throughput']:.2f} req/s")
            print(f"      âœ“ CPUä½¿ç”¨ç‡: {start_system_stats['cpu_percent']:.1f}% â†’ {end_system_stats['cpu_percent']:.1f}%")
            print(f"      âœ“ CPUç©ºé—²ç‡: {start_system_stats['cpu_idle']:.1f}% â†’ {end_system_stats['cpu_idle']:.1f}%")
            print(f"      âœ“ å†…å­˜ä½¿ç”¨ç‡: {start_system_stats['memory_percent']:.1f}% â†’ {end_system_stats['memory_percent']:.1f}%")

            if metrics["failed_requests"] > 0:
                print(f"      âŒ å¤±è´¥è¯·æ±‚æ•°: {metrics['failed_requests']}")

            return test_results

    def should_stop_test(self, current_result: Dict[str, Any], previous_result: Dict[str, Any] = None) -> bool:
        """åˆ¤æ–­æ˜¯å¦åº”è¯¥åœæ­¢æµ‹è¯• - ç°åœ¨ä»…ç”¨äºè­¦å‘Šï¼Œä¸åœæ­¢æµ‹è¯•"""
        # åœæ­¢æ¡ä»¶ï¼š
        # 1. CPUç©ºé—²ç‡ä½äº30%
        # 2. é”™è¯¯ç‡è¶…è¿‡5%
        # 3. å“åº”æ—¶é—´å¤§å¹…å¢åŠ ï¼ˆè¶…è¿‡å‰ä¸€ä¸ªé˜¶æ®µçš„2å€ï¼‰
        # 4. å†…å­˜ä½¿ç”¨ç‡è¶…è¿‡90%

        end_cpu_idle = current_result["end_cpu_idle"]
        success_rate = current_result["success_rate"]
        avg_response_time = current_result["avg_response_time"]
        memory_percent = current_result["end_memory_percent"]

        warnings = []

        if end_cpu_idle < 30:
            warnings.append(f"âš ï¸ CPUç©ºé—²ç‡è¿‡ä½ ({end_cpu_idle:.1f}%)")

        if success_rate < 95:
            warnings.append(f"âš ï¸ é”™è¯¯ç‡è¿‡é«˜ ({100-success_rate:.1f}%)")

        if previous_result and avg_response_time > previous_result["avg_response_time"] * 2:
            warnings.append(f"âš ï¸ å“åº”æ—¶é—´å¤§å¹…å¢åŠ  ({avg_response_time:.3f}s vs {previous_result['avg_response_time']:.3f}s)")

        if memory_percent > 90:
            warnings.append(f"âš ï¸ å†…å­˜ä½¿ç”¨ç‡è¿‡é«˜ ({memory_percent:.1f}%)")

        if warnings:
            print(f"\nâš ï¸ æ€§èƒ½è­¦å‘Š:")
            for warning in warnings:
                print(f"   {warning}")
            return True  # æ ‡è®°è¾¾åˆ°æ€§èƒ½æé™ï¼Œä½†ä¸åœæ­¢æµ‹è¯•

        return False

    async def run_ramp_up_test(self):
        """è¿è¡Œå®Œæ•´çš„é˜¶æ¢¯å¼è´Ÿè½½æµ‹è¯•"""
        print("ğŸ”¥ å¼€å§‹é˜¶æ¢¯å¼å‹åŠ›æµ‹è¯•")
        print("=" * 60)

        # æµ‹è¯•é˜¶æ®µé…ç½®
        test_phases = [
            {"concurrency": 10, "duration": 20, "name": "ä½è´Ÿè½½æµ‹è¯•"},
            {"concurrency": 20, "duration": 20, "name": "ä¸­ç­‰è´Ÿè½½æµ‹è¯•"},
            {"concurrency": 30, "duration": 20, "name": "é«˜è´Ÿè½½æµ‹è¯•"},
            {"concurrency": 40, "duration": 20, "name": "é«˜è´Ÿè½½æµ‹è¯•"},
            {"concurrency": 50, "duration": 20, "name": "æé«˜è´Ÿè½½æµ‹è¯•"},
            {"concurrency": 75, "duration": 20, "name": "æé™è´Ÿè½½æµ‹è¯•"},
            {"concurrency": 100, "duration": 20, "name": "è¶…æé™æµ‹è¯•"},
            {"concurrency": 150, "duration": 20, "name": "å´©æºƒæµ‹è¯•"},
            {"concurrency": 200, "duration": 20, "name": "å‹åŠ›æµ‹è¯•"},
        ]

        # å¯åŠ¨ç³»ç»Ÿç›‘æ§
        import threading
        def monitor_system():
            while hasattr(self, '_monitoring') and self._monitoring:
                self.system_monitor.record_stats()
                time.sleep(1)

        self._monitoring = True
        monitor_thread = threading.Thread(target=monitor_system, daemon=True)
        monitor_thread.start()

        try:
            previous_result = None
            performance_limit_reached = False

            for i, phase in enumerate(test_phases):
                # è¿è¡Œæµ‹è¯•é˜¶æ®µ
                result = await self.run_single_test_phase(
                    concurrency=phase["concurrency"],
                    duration=phase["duration"],
                    phase_name=phase["name"]
                )

                self.results.append(result)

                # æ£€æŸ¥æ˜¯å¦è¾¾åˆ°æ€§èƒ½æé™ï¼ˆä»…è­¦å‘Šï¼Œä¸åœæ­¢ï¼‰
                if self.should_stop_test(result, previous_result):
                    if not performance_limit_reached:
                        print(f"\nğŸ¯ é¦–æ¬¡è¾¾åˆ°æ€§èƒ½æé™æ ‡è®°ç‚¹: {phase['name']}")
                        performance_limit_reached = True

                # å¦‚æœæ˜¯æœ€åä¸€ä¸ªé˜¶æ®µï¼Œä¹Ÿåœæ­¢
                if i == len(test_phases) - 1:
                    print(f"\nğŸ å·²å®Œæˆæ‰€æœ‰æµ‹è¯•é˜¶æ®µ")
                    break

                # é˜¶æ®µé—´ä¼‘æ¯
                print(f"   â³ é˜¶æ®µé—´ä¼‘æ¯ 10 ç§’...")
                await asyncio.sleep(10)

                previous_result = result

        finally:
            self._monitoring = False
            if monitor_thread.is_alive():
                monitor_thread.join(timeout=2)

        return self.results

    def save_results(self, filename: str = "ramp_up_test_results.json"):
        """ä¿å­˜æµ‹è¯•ç»“æœ"""
        results_data = {
            "test_info": {
                "base_url": self.base_url,
                "test_time": datetime.now().isoformat(),
                "total_phases": len(self.results)
            },
            "results": self.results,
            "system_monitoring": {
                "cpu_data": self.system_monitor.cpu_data,
                "memory_data": self.system_monitor.memory_data
            }
        }

        with open(filename, 'w', encoding='utf-8') as f:
            json.dump(results_data, f, indent=2, ensure_ascii=False)

        print(f"\nğŸ’¾ æµ‹è¯•ç»“æœå·²ä¿å­˜åˆ°: {filename}")

    def generate_report(self):
        """ç”Ÿæˆæµ‹è¯•æŠ¥å‘Š"""
        if not self.results:
            print("æ²¡æœ‰æµ‹è¯•ç»“æœ")
            return

        print("\n" + "=" * 60)
        print("ğŸ“Š é˜¶æ¢¯å¼å‹åŠ›æµ‹è¯•æŠ¥å‘Š")
        print("=" * 60)

        # åˆ†ææ‰€æœ‰é˜¶æ®µçš„æ€§èƒ½æ‹ç‚¹
        performance_knees = []
        for i, result in enumerate(self.results):
            issues = []
            if result["success_rate"] < 95:
                issues.append(f"é”™è¯¯ç‡: {100-result['success_rate']:.1f}%")
            if result["end_cpu_idle"] < 30:
                issues.append(f"CPUç©ºé—²ç‡: {result['end_cpu_idle']:.1f}%")
            if result["end_memory_percent"] > 90:
                issues.append(f"å†…å­˜ä½¿ç”¨ç‡: {result['end_memory_percent']:.1f}%")

            if issues:
                performance_knees.append({
                    "phase": i + 1,
                    "concurrency": result["concurrency"],
                    "throughput": result["throughput"],
                    "success_rate": result["success_rate"],
                    "issues": issues
                })

        if performance_knees:
            print(f"ğŸ¯ å‘ç° {len(performance_knees)} ä¸ªæ€§èƒ½æ‹ç‚¹:")
            for knee in performance_knees:
                print(f"   ç¬¬ {knee['phase']} é˜¶æ®µ ({knee['concurrency']} å¹¶å‘ç”¨æˆ·):")
                print(f"     â€¢ ååé‡: {knee['throughput']:.2f} req/s")
                print(f"     â€¢ æˆåŠŸç‡: {knee['success_rate']:.1f}%")
                print(f"     â€¢ é—®é¢˜: {', '.join(knee['issues'])}")
        else:
            print("ğŸ‰ åœ¨æµ‹è¯•èŒƒå›´å†…æœªå‘ç°æ˜æ˜¾çš„æ€§èƒ½æ‹ç‚¹")

        # æ‰¾åˆ°æœ€ä½³æ€§èƒ½ç‚¹ï¼ˆç»¼åˆè€ƒè™‘ååé‡å’ŒæˆåŠŸç‡ï¼‰
        best_throughput = max(self.results, key=lambda x: x["throughput"])
        best_success_rate = max(self.results, key=lambda x: x["success_rate"])

        print(f"\nğŸ† æœ€ä½³æ€§èƒ½ç‚¹:")
        print(f"   â€¢ æœ€é«˜ååé‡: {best_throughput['concurrency']} å¹¶å‘ç”¨æˆ·, {best_throughput['throughput']:.2f} req/s")
        print(f"   â€¢ æœ€é«˜æˆåŠŸç‡: {best_success_rate['concurrency']} å¹¶å‘ç”¨æˆ·, {best_success_rate['success_rate']:.1f}%")

        # æ€§èƒ½è¶‹åŠ¿åˆ†æ
        print(f"\nğŸ“ˆ æ€§èƒ½è¶‹åŠ¿åˆ†æ:")
        print("   å¹¶å‘ç”¨æˆ· | æˆåŠŸç‡ | ååé‡ | å“åº”æ—¶é—´ | å†…å­˜ä½¿ç”¨")
        print("   " + "-" * 60)
        for result in self.results:
            print(f"   {result['concurrency']:8d} | {result['success_rate']:5.1f}% | {result['throughput']:6.2f} | {result['avg_response_time']:7.3f}s | {result['end_memory_percent']:7.1f}%")

        # æ€»ç»“
        total_requests = sum(r["total_requests"] for r in self.results)
        total_errors = sum(r["failed_requests"] for r in self.results)
        overall_success_rate = (total_requests - total_errors) / total_requests * 100
        avg_throughput = sum(r["throughput"] for r in self.results) / len(self.results)

        print(f"\nğŸ“Š æµ‹è¯•æ€»ç»“:")
        print(f"   â€¢ æ€»è¯·æ±‚æ•°: {total_requests}")
        print(f"   â€¢ æ€»é”™è¯¯æ•°: {total_errors}")
        print(f"   â€¢ æ•´ä½“æˆåŠŸç‡: {overall_success_rate:.2f}%")
        print(f"   â€¢ å¹³å‡ååé‡: {avg_throughput:.2f} req/s")
        print(f"   â€¢ æµ‹è¯•é˜¶æ®µæ•°: {len(self.results)}")

        # ç»¼åˆè¯„ä¼°
        print(f"\nğŸ” ç»¼åˆæ€§èƒ½è¯„ä¼°:")
        if overall_success_rate >= 95:
            print("   âœ… æ•´ä½“æˆåŠŸç‡è‰¯å¥½")
        else:
            print(f"   âš ï¸ æ•´ä½“æˆåŠŸç‡åä½: {overall_success_rate:.1f}%")

        # æ‰¾å‡ºæ€§èƒ½æœ€ç¨³å®šçš„é˜¶æ®µ
        stable_phases = [r for r in self.results if r["success_rate"] >= 95]
        if stable_phases:
            max_stable_concurrency = max(stable_phases, key=lambda x: x["concurrency"])
            print(f"   âœ… ç³»ç»Ÿåœ¨ {max_stable_concurrency['concurrency']} å¹¶å‘ç”¨æˆ·å†…è¡¨ç°ç¨³å®š")
        else:
            print("   âŒ ç³»ç»Ÿåœ¨æ‰€æœ‰æµ‹è¯•é˜¶æ®µéƒ½å­˜åœ¨æ€§èƒ½é—®é¢˜")


async def main():
    """ä¸»å‡½æ•°"""
    print("ğŸ”¥ ChatBot SSE æœåŠ¡å™¨é˜¶æ¢¯å¼å‹åŠ›æµ‹è¯•")
    print("=" * 60)

    # åˆ›å»ºæµ‹è¯•å™¨
    tester = RampUpLoadTester(base_url="http://localhost:8000")

    # æ£€æŸ¥æœåŠ¡å™¨çŠ¶æ€
    print("ğŸ” æ£€æŸ¥æœåŠ¡å™¨çŠ¶æ€...")
    if not await tester.health_check():
        print("âŒ æœåŠ¡å™¨ä¸å¯ç”¨ï¼Œè¯·æ£€æŸ¥æœåŠ¡å™¨æ˜¯å¦æ­£åœ¨è¿è¡Œ")
        return

    print("âœ… æœåŠ¡å™¨è¿è¡Œæ­£å¸¸")

    # è¿è¡Œæµ‹è¯•
    results = await tester.run_ramp_up_test()

    # ä¿å­˜ç»“æœ
    tester.save_results()

    # ç”ŸæˆæŠ¥å‘Š
    tester.generate_report()


if __name__ == "__main__":
    asyncio.run(main())